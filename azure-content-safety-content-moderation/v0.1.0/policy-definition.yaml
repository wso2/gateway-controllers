name: AzureContentSafetyContentModeration
version: v0.1.0
description: |
  Validates request or response body content against Azure Content Safety API for content moderation.
  Supports detection of hate speech, sexual content, self-harm, and violence with configurable severity thresholds.
  Supports JSONPath extraction to validate specific fields within JSON payloads.
  Supports separate configuration for request and response phases.

parameters:
  type: object
  properties:
    request:
      type: object
      description: Configuration for request phase validation
      properties:
        jsonPath:
          type: string
          description: |
            JSONPath expression to extract a specific value from JSON payload.
            If empty, validates the entire payload as a string.
            Examples: "$.message", "$.data.content", "$.items[0].text"
          default: ""
        passthroughOnError:
          type: boolean
          description: |
            If true, allows requests to proceed if Azure Content Safety API call fails.
            If false (default), blocks requests on API errors.
          default: false
        showAssessment:
          type: boolean
          description: |
            If true, includes detailed assessment information in error responses.
            If false, returns minimal error information.
          default: false
        hateCategory:
          type: integer
          description: |
            Severity threshold for hate category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
        sexualCategory:
          type: integer
          description: |
            Severity threshold for sexual category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
        selfHarmCategory:
          type: integer
          description: |
            Severity threshold for self-harm category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
        violenceCategory:
          type: integer
          description: |
            Severity threshold for violence category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
    response:
      type: object
      description: Configuration for response phase validation
      properties:
        jsonPath:
          type: string
          description: |
            JSONPath expression to extract a specific value from JSON payload.
            If empty, validates the entire payload as a string.
            Examples: "$.message", "$.data.content", "$.items[0].text"
          default: ""
        passthroughOnError:
          type: boolean
          description: |
            If true, allows requests to proceed if Azure Content Safety API call fails.
            If false (default), blocks requests on API errors.
          default: false
        showAssessment:
          type: boolean
          description: |
            If true, includes detailed assessment information in error responses.
            If false, returns minimal error information.
          default: false
        hateCategory:
          type: integer
          description: |
            Severity threshold for hate category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
        sexualCategory:
          type: integer
          description: |
            Severity threshold for sexual category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
        selfHarmCategory:
          type: integer
          description: |
            Severity threshold for self-harm category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1
        violenceCategory:
          type: integer
          description: |
            Severity threshold for violence category (0-7).
            -1 disables this category.
            Content with severity >= threshold will be blocked.
          minimum: -1
          maximum: 7
          default: -1

systemParameters:
  type: object
  additionalProperties: false
  properties:
    azureContentSafetyEndpoint:
      type: string
      format: uri
      description: Azure Content Safety API endpoint URL (without trailing slash, e.g., https://your-resource.cognitiveservices.azure.com).
      minLength: 1
      "wso2/defaultValue": "${config.azurecontentsafety_endpoint}"
    azureContentSafetyKey:
      type: string
      description: Azure Content Safety API subscription key for authentication.
      minLength: 1
      "wso2/defaultValue": "${config.azurecontentsafety_key}"
  required:
    - azureContentSafetyEndpoint
    - azureContentSafetyKey
